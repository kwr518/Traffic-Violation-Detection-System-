# íŒŒì¼ëª…: plate_ocr.py

import cv2
import numpy as np
import re
import logging
import os
from collections import Counter
from PIL import Image, ImageDraw, ImageFont
from ultralytics import YOLO

# ë¡œê¹… ì„¤ì •
logger = logging.getLogger(__name__)
# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# =====================================================================
# 1. ì „ì²˜ë¦¬ í´ë˜ìŠ¤ (EasyOCR ìµœì í™”)
# =====================================================================
class PlateImagePreprocessor:
    @staticmethod
    def preprocess_for_ocr(plate_image: np.ndarray) -> np.ndarray:
        # Step 1: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(plate_image.shape) == 3:
            gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_image

        # Step 2: ì´ë¯¸ì§€ í™•ëŒ€ (2ë°°) - ì‘ì€ ë²ˆí˜¸íŒ ì¸ì‹ë¥  í–¥ìƒ
        enlarged = cv2.resize(gray, None, fx=2.0, fy=2.0, interpolation=cv2.INTER_CUBIC)
        
        # Step 3: ëª…ì•” ê°œì„  (CLAHE)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        enhanced = clahe.apply(enlarged)
        
        # Step 4: ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.fastNlMeansDenoising(enhanced, h=10, templateWindowSize=7, searchWindowSize=21)
        
        return denoised

# =====================================================================
# 2. ê¸°ìš¸ê¸° ë³´ì • í´ë˜ìŠ¤
# =====================================================================
class PlateDeskewer:
    @staticmethod
    def deskew_plate(image: np.ndarray) -> np.ndarray:
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
            
        edges = cv2.Canny(gray, 50, 150)
        lines = cv2.HoughLines(edges, 1, np.pi/180, 50)
        
        if lines is None or len(lines) == 0:
            return image
        
        angles = []
        for line in lines:
            rho, theta = line[0]
            angle = np.degrees(theta) - 90
            angles.append(angle)
        
        if not angles: return image
        
        angles = sorted(angles)
        median_angle = np.median(angles[len(angles)//4:-len(angles)//4]) if len(angles) > 4 else np.median(angles)
        
        if abs(median_angle) > 30: return image
        
        h, w = image.shape[:2]
        center = (w // 2, h // 2)
        rotation_matrix = cv2.getRotationMatrix2D(center, median_angle, 1.0)
        
        rotated = cv2.warpAffine(image, rotation_matrix, (w, h), 
                                 borderMode=cv2.BORDER_CONSTANT, borderValue=(255, 255, 255))
        return rotated

# =====================================================================
# 3. ë‹¤ì¤‘ ì—”ì§„ OCR (Paddle + EasyOCR)
# =====================================================================
class MultiEngineOCR:
    def __init__(self):
        self.engines = {}
        self._initialize_engines()
    
    def _initialize_engines(self):
        # 1. PaddleOCR ì‹œë„
        try:
            from paddleocr import PaddleOCR
            import logging as py_logging
            py_logging.getLogger("ppocr").setLevel(py_logging.ERROR)
            
            self.engines['paddle'] = PaddleOCR(
                use_angle_cls=True, lang='korean', use_gpu=False, show_log=False
            )
        except Exception as e:
            logger.warning(f"âš ï¸ PaddleOCR ë¡œë“œ ì‹¤íŒ¨ (EasyOCR ì‚¬ìš©): {e}")

        # 2. EasyOCR ì‹œë„ (í•„ìˆ˜)
        try:
            import easyocr
            self.engines['easy'] = easyocr.Reader(['ko', 'en'], gpu=False)
        except Exception as e:
            logger.error(f"âŒ EasyOCR ë¡œë“œ ì‹¤íŒ¨: {e}")

    def recognize_with_all_engines(self, plate_image: np.ndarray):
        results = {}
        confidences = {}

        # PaddleOCR
        if 'paddle' in self.engines:
            try:
                p_res = self.engines['paddle'].ocr(plate_image, cls=True)
                if p_res and p_res[0]:
                    txts = [line[1][0] for line in p_res[0]]
                    confs = [line[1][1] for line in p_res[0]]
                    results['paddle'] = "".join(txts)
                    confidences['paddle'] = np.mean(confs)
            except: pass

        # EasyOCR
        if 'easy' in self.engines:
            try:
                e_res = self.engines['easy'].readtext(plate_image)
                if e_res:
                    txts = [res[1] for res in e_res]
                    confs = [res[2] for res in e_res]
                    results['easy'] = "".join(txts)
                    confidences['easy'] = np.mean(confs)
            except: pass

        if results:
            best_engine = max(confidences.items(), key=lambda x: x[1])[0]
            return {
                'text': results[best_engine],
                'engine': best_engine,
                'confidence': confidences[best_engine]
            }
        return {'text': '', 'engine': 'none', 'confidence': 0.0}

# =====================================================================
# 4. í›„ì²˜ë¦¬ (ì •ê·œí™”)
# =====================================================================
class OCRPostProcessor:
    @staticmethod
    def postprocess_korean_plate(text: str) -> str:
        if not text: return ''
        text = text.replace(' ', '').replace('-', '').replace('.', '')
        
        # ì˜¤ì¸ì‹ ë¬¸ì êµì •
        corrections = {'O': '0', 'I': '1', 'S': '5', 'l': '1', 'Z': '2', 'B': '8', 'G': '9', 'A': '4', 'T': '1', 'o': '0'}
        for wrong, correct in corrections.items():
            text = text.replace(wrong, correct)
            
        # í•œê¸€, ìˆ«ìë§Œ ë‚¨ê¹€
        text = re.sub(r'[^ê°€-í£0-9]', '', text)
        return text
    
    @staticmethod
    def validate_plate_format(text: str):
        if not text: return False, "í…ìŠ¤íŠ¸ ì—†ìŒ"
        if len(text) < 7: return False, "ê¸¸ì´ ì§§ìŒ"
        if not re.findall(r'[ê°€-í£]', text): return False, "í•œê¸€ ì—†ìŒ"
        if len(re.findall(r'\d', text)) < 6: return False, "ìˆ«ì ë¶€ì¡±"
        return True, "ìœ íš¨í•¨"

# =====================================================================
# 5. í†µí•© OCR íŒŒì´í”„ë¼ì¸
# =====================================================================
class HighAccuracyOCR:
    def __init__(self):
        self.preprocessor = PlateImagePreprocessor()
        self.deskewer = PlateDeskewer()
        self.multi_ocr = MultiEngineOCR()
        self.postprocessor = OCRPostProcessor()
    
    def recognize_plate(self, plate_image: np.ndarray):
        # 1. ê°ë„ ë³´ì •
        plate_image = self.deskewer.deskew_plate(plate_image)
        # 2. ì „ì²˜ë¦¬
        preprocessed = self.preprocessor.preprocess_for_ocr(plate_image)
        # 3. ì¸ì‹
        ocr_result = self.multi_ocr.recognize_with_all_engines(preprocessed)
        # 4. í›„ì²˜ë¦¬
        raw_text = ocr_result['text']
        normalized = self.postprocessor.postprocess_korean_plate(raw_text)
        is_valid, msg = self.postprocessor.validate_plate_format(normalized)
        
        return {
            'normalized_text': normalized,
            'is_valid': is_valid,
            'ocr_confidence': ocr_result.get('confidence', 0.0)
        }

# =====================================================================
# 6. [í•µì‹¬] ì„œë²„ ì—°ë™ìš© ëª¨ë“ˆ (YOLO + Voting í¬í•¨)
# =====================================================================
class PlateRecognizerModule:
    """ì„œë²„ì—ì„œ ìœ„ë°˜ êµ¬ê°„ ì˜ìƒì„ ë°›ì•„ ë²ˆí˜¸íŒì„ ì¶”ì¶œí•˜ëŠ” í´ë˜ìŠ¤"""
    def __init__(self, model_path: str):
        print(f"ğŸ”§ ë²ˆí˜¸íŒ ì¸ì‹ ëª¨ë“ˆ ì´ˆê¸°í™” ì¤‘... (YOLO: {model_path})")
        self.model = YOLO(model_path) 
        self.ocr = HighAccuracyOCR()
        
    def process_segment(self, video_path: str, start_frame: int, count: int):
        """
        íŠ¹ì • ì˜ìƒì˜ íŠ¹ì • êµ¬ê°„(start_frameë¶€í„° countë§Œí¼)ë§Œ ì½ì–´ì„œ
        ê°€ì¥ ë§ì´ ê²€ì¶œëœ(Voting) ë²ˆí˜¸íŒ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜
        """
        cap = cv2.VideoCapture(video_path)
        cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)
        
        detected_plates = []
        
        # print(f"ğŸ” ë²ˆí˜¸íŒ ì •ë°€ ë¶„ì„ ì‹œì‘ (êµ¬ê°„: {start_frame} ~ {start_frame+count})")
        
        for _ in range(count):
            ret, frame = cap.read()
            if not ret: break
            
            # 1. YOLOë¡œ ë²ˆí˜¸íŒ ìœ„ì¹˜ íƒì§€
            results = self.model(frame, conf=0.4, verbose=False)
            if not results: continue
            
            for box in results[0].boxes:
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                
                # ì¢Œí‘œ ë³´ì •
                h, w = frame.shape[:2]
                pad = 5
                crop = frame[max(0, y1-pad):min(h, y2+pad), max(0, x1-pad):min(w, x2+pad)]
                
                if crop.size == 0: continue

                # 2. OCR ìˆ˜í–‰
                ocr_res = self.ocr.recognize_plate(crop)
                
                if ocr_res['is_valid']:
                    detected_plates.append(ocr_res['normalized_text'])

        cap.release()
        
        # 3. íˆ¬í‘œ (ìµœë¹ˆê°’ ì„ ì •)
        if detected_plates:
            # ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë²ˆí˜¸ì™€ íšŸìˆ˜
            most_common = Counter(detected_plates).most_common(1)[0]
            plate_text, count = most_common
            
            # ìµœì†Œ 2ë²ˆ ì´ìƒì€ ë™ì¼í•˜ê²Œ ì¸ì‹ë˜ì–´ì•¼ ì¸ì •
            if count >= 2:
                return plate_text
            else:
                return f"{plate_text}(ë¶ˆí™•ì‹¤)"
        
        return "ì‹ë³„ë¶ˆê°€"